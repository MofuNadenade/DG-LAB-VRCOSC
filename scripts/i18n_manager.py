#!/usr/bin/env python3
"""
æœ¬åœ°åŒ–ç®¡ç†å·¥å…·

åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æå–ä»£ç ä¸­ä½¿ç”¨çš„æœ¬åœ°åŒ–é”®
2. æå–è¯­è¨€æ–‡ä»¶ä¸­å®šä¹‰çš„é”®
3. æŸ¥æ‰¾æœªä½¿ç”¨çš„æœ¬åœ°åŒ–é”®
4. åˆ†ææœ¬åœ°åŒ–é”®çš„ä½¿ç”¨æƒ…å†µ
5. éªŒè¯è¯­è¨€æ–‡ä»¶çš„ä¸€è‡´æ€§
"""

import re
import os
import sys
import argparse
from pathlib import Path
from typing import Set, Dict, List, Tuple, Any
from ruamel.yaml import YAML

yaml_loader = YAML(typ='safe')
yaml_writer = YAML()
yaml_writer.preserve_quotes = True
yaml_writer.default_flow_style = False

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def flatten_dict(d: Dict[str, Any], parent_key: str = '', sep: str = '.') -> Dict[str, Any]:
    """å°†åµŒå¥—å­—å…¸æ‰å¹³åŒ–ä¸ºç‚¹åˆ†éš”çš„é”®"""
    items: List[Tuple[str, Any]] = []
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())  # type: ignore
        else:
            items.append((new_key, v))
    return dict(items)

def extract_keys_from_yaml(file_path: str) -> Set[str]:
    """ä»YAMLæ–‡ä»¶ä¸­æå–æ‰€æœ‰é”®"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = yaml_loader.load(f)  # type: ignore
            if data:
                flat_data = flatten_dict(data)  # type: ignore
                return set(flat_data.keys())
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    return set()

def extract_keys_from_file(file_path: str) -> Set[str]:
    """ä»å•ä¸ªPythonæ–‡ä»¶ä¸­æå–æœ¬åœ°åŒ–é”®"""
    keys: Set[str] = set()
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # åŒ¹é… translate("key") å’Œ translate('key') æ¨¡å¼
            pattern = r'translate\(["\']([^"\']+)["\']\)'
            matches = re.findall(pattern, content)
            keys.update(matches)
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    return keys

def extract_used_keys_by_file(src_dir: str) -> Dict[str, Set[str]]:
    """æŒ‰æ–‡ä»¶åˆ†ç»„æå–srcç›®å½•ä¸‹æ‰€æœ‰Pythonæ–‡ä»¶ä¸­ä½¿ç”¨çš„æœ¬åœ°åŒ–é”®"""
    file_keys: Dict[str, Set[str]] = {}
    
    for root, _, files in os.walk(src_dir):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                keys = extract_keys_from_file(file_path)
                if keys:  # åªè®°å½•æœ‰æœ¬åœ°åŒ–é”®çš„æ–‡ä»¶
                    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºé”®ï¼Œä¾¿äºæ˜¾ç¤º
                    relative_path = os.path.relpath(file_path, src_dir)
                    file_keys[relative_path] = keys
    
    return file_keys

def extract_used_keys(src_dir: str) -> Set[str]:
    """æå–srcç›®å½•ä¸‹æ‰€æœ‰Pythonæ–‡ä»¶ä¸­ä½¿ç”¨çš„æœ¬åœ°åŒ–é”®"""
    all_keys: Set[str] = set()
    
    for root, _, files in os.walk(src_dir):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                keys = extract_keys_from_file(file_path)
                all_keys.update(keys)
    
    return all_keys

def extract_defined_keys(locale_files: List[str]) -> Set[str]:
    """æå–æ‰€æœ‰è¯­è¨€æ–‡ä»¶ä¸­å®šä¹‰çš„é”®"""
    all_defined_keys: Set[str] = set()
    
    for file_path in locale_files:
        if Path(file_path).exists():
            keys = extract_keys_from_yaml(file_path)
            all_defined_keys.update(keys)
    
    return all_defined_keys

def check_consistency(locale_files: List[str]) -> Tuple[bool, List[str]]:
    """æ£€æŸ¥æ‰€æœ‰è¯­è¨€æ–‡ä»¶çš„é”®æ˜¯å¦ä¸€è‡´"""
    errors: List[str] = []
    file_keys: Dict[str, Set[str]] = {}
    
    # æå–æ¯ä¸ªæ–‡ä»¶çš„é”®
    for file_path in locale_files:
        if Path(file_path).exists():
            file_keys[file_path] = extract_keys_from_yaml(file_path)
        else:
            errors.append(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if len(file_keys) < 2:
        return True, errors
    
    # æ¯”è¾ƒé”®çš„ä¸€è‡´æ€§
    files = list(file_keys.keys())
    base_file = files[0]
    base_keys = file_keys[base_file]
    
    for other_file in files[1:]:
        other_keys = file_keys[other_file]
        
        # æ£€æŸ¥ç¼ºå¤±çš„é”®
        missing_in_other = base_keys - other_keys
        missing_in_base = other_keys - base_keys
        
        if missing_in_other:
            errors.append(f"{other_file} ç¼ºå°‘é”®: {sorted(missing_in_other)}")
        
        if missing_in_base:
            errors.append(f"{base_file} ç¼ºå°‘é”®: {sorted(missing_in_base)}")
    
    return len(errors) == 0, errors

def analyze_usage(src_dir: str, locale_files: List[str]) -> Dict[str, Any]:
    """åˆ†ææœ¬åœ°åŒ–é”®çš„ä½¿ç”¨æƒ…å†µ"""
    used_keys = extract_used_keys(src_dir)
    defined_keys = extract_defined_keys(locale_files)
    unused_keys = defined_keys - used_keys
    missing_keys = used_keys - defined_keys
    
    return {
        'used_keys': used_keys,
        'defined_keys': defined_keys,
        'unused_keys': unused_keys,
        'missing_keys': missing_keys,
        'total_used': len(used_keys),
        'total_defined': len(defined_keys),
        'total_unused': len(unused_keys),
        'total_missing': len(missing_keys)
    }

def print_usage_report(analysis: Dict[str, Any]) -> None:
    """æ‰“å°ä½¿ç”¨æƒ…å†µæŠ¥å‘Š"""
    print("=== æœ¬åœ°åŒ–é”®ä½¿ç”¨æƒ…å†µåˆ†æ ===")
    print(f"å®šä¹‰çš„é”®æ€»æ•°: {analysis['total_defined']}")
    print(f"ä½¿ç”¨çš„é”®æ€»æ•°: {analysis['total_used']}")
    print(f"æœªä½¿ç”¨çš„é”®æ€»æ•°: {analysis['total_unused']}")
    print(f"ç¼ºå¤±çš„é”®æ€»æ•°: {analysis['total_missing']}")
    
    if analysis['unused_keys']:
        print(f"\n=== æœªä½¿ç”¨çš„é”® ({analysis['total_unused']} ä¸ª) ===")
        for key in sorted(analysis['unused_keys']):
            print(key)
    else:
        print("\nâœ… æ‰€æœ‰å®šä¹‰çš„é”®éƒ½è¢«ä½¿ç”¨äº†ï¼")
    
    if analysis['missing_keys']:
        print(f"\n=== ç¼ºå¤±çš„é”® ({analysis['total_missing']} ä¸ª) ===")
        for key in sorted(analysis['missing_keys']):
            print(key)
    else:
        print("\nâœ… æ‰€æœ‰ä½¿ç”¨çš„é”®éƒ½å·²å®šä¹‰ï¼")

def print_keys_by_file(file_keys: Dict[str, Set[str]]) -> None:
    """æ‰“å°æŒ‰æ–‡ä»¶åˆ†ç»„çš„æœ¬åœ°åŒ–é”®ä½¿ç”¨æƒ…å†µ"""
    total_files = len(file_keys)
    total_keys = sum(len(keys) for keys in file_keys.values())
    
    print(f"=== æŒ‰æ–‡ä»¶åˆ†ç»„çš„æœ¬åœ°åŒ–é”®ä½¿ç”¨æƒ…å†µ ===")
    print(f"åŒ…å«æœ¬åœ°åŒ–é”®çš„æ–‡ä»¶æ•°: {total_files}")
    print(f"ä½¿ç”¨çš„é”®æ€»æ•°: {total_keys}")
    
    if not file_keys:
        print("\nâœ… æ²¡æœ‰æ‰¾åˆ°ä½¿ç”¨æœ¬åœ°åŒ–é”®çš„æ–‡ä»¶ï¼")
        return
    
    # æŒ‰æ–‡ä»¶è·¯å¾„æ’åº
    for file_path in sorted(file_keys.keys()):
        keys = file_keys[file_path]
        print(f"\nğŸ“ {file_path} ({len(keys)} ä¸ªé”®)")
        for key in sorted(keys):
            print(f"  - {key}")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ–‡ä»¶æ•°é‡: {total_files}")
    print(f"  é”®æ€»æ•°: {total_keys}")
    if total_files > 0:
        print(f"  å¹³å‡æ¯æ–‡ä»¶: {total_keys / total_files:.1f} ä¸ªé”®")

def remove_keys_from_dict(data: Any, keys_to_remove: Set[str], parent_key: str = '') -> Dict[str, Any]:
    """ä»åµŒå¥—å­—å…¸ä¸­ç§»é™¤æŒ‡å®šçš„é”®"""
    result: Dict[str, Any] = {}

    for k, v in data.items():
        current_key = f"{parent_key}.{k}" if parent_key else k
        
        if current_key in keys_to_remove:
            continue  # è·³è¿‡è¦åˆ é™¤çš„é”®
        
        if isinstance(v, dict):
            # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
            nested_result = remove_keys_from_dict(v, keys_to_remove, current_key)
            if nested_result:  # åªæœ‰å½“åµŒå¥—å­—å…¸ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
                result[k] = nested_result
        else:
            result[k] = v
    
    return result

def clean_unused_keys(locale_files: List[str], unused_keys: Set[str], dry_run: bool = True) -> None:
    """æ¸…ç†æœªä½¿ç”¨çš„é”®"""
    print(f"\n=== æ¸…ç†æœªä½¿ç”¨çš„é”® ({'é¢„è§ˆæ¨¡å¼' if dry_run else 'æ‰§è¡Œæ¨¡å¼'}) ===")
    
    if not unused_keys:
        print("âœ… æ²¡æœ‰æœªä½¿ç”¨çš„é”®éœ€è¦æ¸…ç†ï¼")
        return
    
    for locale_file in locale_files:
        print(f"\nå¤„ç†æ–‡ä»¶: {locale_file}")
        
        try:
            # è¯»å–åŸå§‹æ•°æ®
            with open(locale_file, 'r', encoding='utf-8') as f:
                original_data = yaml_writer.load(f)  # type: ignore
            
            if not original_data:
                print(f"  âš ï¸ æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # ç§»é™¤æœªä½¿ç”¨çš„é”®
            cleaned_data = remove_keys_from_dict(original_data, unused_keys)
            
            # è®¡ç®—ç§»é™¤çš„é”®æ•°é‡
            original_keys = set(flatten_dict(original_data).keys())  # type: ignore
            removed_keys = original_keys & unused_keys
            
            if removed_keys:
                print(f"  å°†ç§»é™¤ {len(removed_keys)} ä¸ªé”®:")
                for key in sorted(removed_keys):
                    print(f"    - {key}")
                
                if not dry_run:
                    # å†™å…¥æ¸…ç†åçš„æ•°æ®
                    with open(locale_file, 'w', encoding='utf-8') as f:
                        yaml_writer.dump(cleaned_data, f)  # type: ignore
                    print(f"  âœ… å·²æ›´æ–°æ–‡ä»¶")
                else:
                    print(f"  ğŸ“‹ é¢„è§ˆå®Œæˆï¼ˆç§»é™¤ --dry-run æ‰§è¡Œå®é™…æ¸…ç†ï¼‰")
            else:
                print(f"  âœ… æ­¤æ–‡ä»¶ä¸­æ²¡æœ‰æœªä½¿ç”¨çš„é”®")
                
        except Exception as e:
            print(f"  âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    if dry_run:
        print(f"\nğŸ“‹ é¢„è§ˆå®Œæˆï¼è¦æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°")
    else:
        print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼å·²ä»æ‰€æœ‰è¯­è¨€æ–‡ä»¶ä¸­ç§»é™¤ {len(unused_keys)} ä¸ªæœªä½¿ç”¨çš„é”®")

def set_nested_value(data: Any, key_path: str, value: Any) -> None:
    """åœ¨åµŒå¥—å­—å…¸ä¸­è®¾ç½®å€¼"""
    keys = key_path.split('.')
    current = data
    
    # å¯¼èˆªåˆ°çˆ¶çº§å­—å…¸
    for key in keys[:-1]:
        if key not in current:
            current[key] = {}
        elif not isinstance(current[key], dict):
            # å¦‚æœè·¯å¾„ä¸Šçš„é”®å·²å­˜åœ¨ä¸”ä¸æ˜¯å­—å…¸ï¼Œåˆ™æ— æ³•ç»§ç»­
            raise ValueError(f"æ— æ³•åœ¨è·¯å¾„ '{key_path}' è®¾ç½®å€¼ï¼š'{key}' ä¸æ˜¯å­—å…¸")
        current = current[key]
    
    # è®¾ç½®æœ€ç»ˆå€¼
    current[keys[-1]] = value

def get_nested_value(data: Any, key_path: str) -> Any:
    """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼"""
    keys = key_path.split('.')
    current = data
    
    for key in keys:
        if not isinstance(current, dict) or key not in current:
            raise KeyError(f"é”® '{key_path}' ä¸å­˜åœ¨")
        current = current[key]  # type: ignore
    
    return current  # type: ignore

def delete_nested_key(data: Any, key_path: str) -> bool:
    """ä»åµŒå¥—å­—å…¸ä¸­åˆ é™¤é”®ï¼Œè¿”å›æ˜¯å¦æˆåŠŸåˆ é™¤"""
    keys = key_path.split('.')
    current = data
    
    # å¯¼èˆªåˆ°çˆ¶çº§å­—å…¸
    try:
        for key in keys[:-1]:
            if not isinstance(current, dict) or key not in current:
                return False
            current = current[key]  # type: ignore
        
        # åˆ é™¤æœ€ç»ˆé”®
        if isinstance(current, dict) and keys[-1] in current:
            del current[keys[-1]]
            return True
        return False
    except Exception:
        return False

def rename_key_in_files(locale_files: List[str], old_key: str, new_key: str, dry_run: bool = True) -> None:
    """åœ¨æ‰€æœ‰è¯­è¨€æ–‡ä»¶ä¸­é‡å‘½åé”®"""
    print(f"\n=== é‡å‘½åé”® {'(é¢„è§ˆæ¨¡å¼)' if dry_run else '(æ‰§è¡Œæ¨¡å¼)'} ===")
    print(f"ä»: {old_key}")
    print(f"åˆ°: {new_key}")
    
    if old_key == new_key:
        print("âŒ æ–°æ—§é”®åç›¸åŒï¼Œæ— éœ€é‡å‘½å")
        return
    
    success_count = 0
    error_count = 0
    
    for locale_file in locale_files:
        if not Path(locale_file).exists():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {locale_file}")
            continue
            
        try:
            # è¯»å–æ–‡ä»¶
            with open(locale_file, 'r', encoding='utf-8') as f:
                data: Any = yaml_writer.load(f)  # type: ignore
            
            if not data or not isinstance(data, dict):
                print(f"âš ï¸ æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼æ— æ•ˆï¼Œè·³è¿‡: {locale_file}")
                continue
            
            # æ£€æŸ¥æ—§é”®æ˜¯å¦å­˜åœ¨
            try:
                value = get_nested_value(data, old_key)
            except KeyError:
                print(f"âš ï¸ é”® '{old_key}' åœ¨æ–‡ä»¶ {locale_file} ä¸­ä¸å­˜åœ¨")
                continue
            
            # æ£€æŸ¥æ–°é”®æ˜¯å¦å·²å­˜åœ¨
            try:
                get_nested_value(data, new_key)
                print(f"âŒ æ–°é”® '{new_key}' åœ¨æ–‡ä»¶ {locale_file} ä¸­å·²å­˜åœ¨")
                error_count += 1
                continue
            except KeyError:
                pass  # æ–°é”®ä¸å­˜åœ¨ï¼Œè¿™æ˜¯æˆ‘ä»¬æƒ³è¦çš„
            
            print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {locale_file}")
            print(f"  å€¼: {value}")
            
            if not dry_run:
                # è®¾ç½®æ–°é”®
                set_nested_value(data, new_key, value)
                # åˆ é™¤æ—§é”®
                delete_nested_key(data, old_key)
                
                # å†™å›æ–‡ä»¶
                with open(locale_file, 'w', encoding='utf-8') as f:
                    yaml_writer.dump(data, f)  # type: ignore
                
                print(f"  âœ… å·²é‡å‘½å")
                success_count += 1
            else:
                print(f"  ğŸ“‹ é¢„è§ˆï¼šå°†é‡å‘½å")
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {locale_file} æ—¶å‡ºé”™: {e}")
            error_count += 1
    
    if dry_run:
        print(f"\nğŸ“‹ é¢„è§ˆå®Œæˆï¼è¦æ‰§è¡Œå®é™…é‡å‘½åï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°")
    else:
        print(f"\nğŸ‰ é‡å‘½åå®Œæˆï¼æˆåŠŸ: {success_count}, é”™è¯¯: {error_count}")

def move_key_to_group(locale_files: List[str], old_key: str, new_group: str, dry_run: bool = True) -> None:
    """å°†é”®ç§»åŠ¨åˆ°æ–°çš„åˆ†ç»„ä¸­ï¼Œä¿æŒé”®åä¸å˜"""
    # æå–é”®çš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæ–°é”®å
    key_parts = old_key.split('.')
    key_name = key_parts[-1]
    new_key = f"{new_group}.{key_name}"
    
    print(f"\n=== ç§»åŠ¨é”®åˆ°æ–°åˆ†ç»„ {'(é¢„è§ˆæ¨¡å¼)' if dry_run else '(æ‰§è¡Œæ¨¡å¼)'} ===")
    print(f"ä»: {old_key}")
    print(f"åˆ°: {new_key}")
    
    rename_key_in_files(locale_files, old_key, new_key, dry_run)

def batch_rename_keys(locale_files: List[str], mapping_file: str, dry_run: bool = True) -> None:
    """æ‰¹é‡é‡å‘½åé”®ï¼Œä»æ˜ å°„æ–‡ä»¶è¯»å–é‡å‘½åè§„åˆ™"""
    print(f"\n=== æ‰¹é‡é‡å‘½åé”® {'(é¢„è§ˆæ¨¡å¼)' if dry_run else '(æ‰§è¡Œæ¨¡å¼)'} ===")
    
    if not Path(mapping_file).exists():
        print(f"âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
        return
    
    try:
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mappings: Any = yaml_loader.load(f)  # type: ignore
        
        if not mappings or not isinstance(mappings, dict):
            print("âŒ æ˜ å°„æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼æ— æ•ˆ")
            return
        
        # ç±»å‹è½¬æ¢ä¸ºå­—å…¸
        mappings_dict: Dict[str, str] = {}
        for k, v in mappings.items():  # type: ignore
            if isinstance(k, str) and isinstance(v, str):
                mappings_dict[k] = v
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„æ˜ å°„: {k} -> {v}")
        
        print(f"ğŸ“– ä» {mapping_file} è¯»å–åˆ° {len(mappings_dict)} ä¸ªæœ‰æ•ˆé‡å‘½åè§„åˆ™")
        
        success_count = 0
        for old_key, new_key in mappings_dict.items():
            print(f"\n--- å¤„ç†: {old_key} -> {new_key} ---")
            try:
                rename_key_in_files(locale_files, old_key, new_key, dry_run)
                success_count += 1
            except Exception as e:
                print(f"âŒ é‡å‘½åå¤±è´¥: {e}")
        
        print(f"\nğŸ‰ æ‰¹é‡é‡å‘½åå®Œæˆï¼å¤„ç†äº† {success_count}/{len(mappings_dict)} ä¸ªé”®")
        
    except Exception as e:
        print(f"âŒ è¯»å–æ˜ å°„æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def clean_empty_groups(locale_files: List[str], dry_run: bool = True) -> None:
    """æ¸…ç†è¯­è¨€æ–‡ä»¶ä¸­çš„ç©ºåˆ†ç»„"""
    print(f"\n=== æ¸…ç†ç©ºåˆ†ç»„ {'(é¢„è§ˆæ¨¡å¼)' if dry_run else '(æ‰§è¡Œæ¨¡å¼)'} ===")
    
    total_cleaned = 0
    
    for locale_file in locale_files:
        if not Path(locale_file).exists():
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {locale_file}")
            continue
            
        try:
            # è¯»å–æ–‡ä»¶
            with open(locale_file, 'r', encoding='utf-8') as f:
                data: Any = yaml_writer.load(f)  # type: ignore
            
            if not data or not isinstance(data, dict):
                print(f"âš ï¸ æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼æ— æ•ˆï¼Œè·³è¿‡: {locale_file}")
                continue
            
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {locale_file}")
            
            # é€’å½’æ¸…ç†ç©ºç»„
            cleaned_data, removed_count = remove_empty_groups(data)
            
            if removed_count > 0:
                print(f"  å°†æ¸…ç† {removed_count} ä¸ªç©ºåˆ†ç»„")
                total_cleaned += removed_count
                
                if not dry_run:
                    # å†™å›æ–‡ä»¶
                    with open(locale_file, 'w', encoding='utf-8') as f:
                        yaml_writer.dump(cleaned_data, f)  # type: ignore
                    print(f"  âœ… å·²æ¸…ç†")
                else:
                    print(f"  ğŸ“‹ é¢„è§ˆå®Œæˆ")
            else:
                print(f"  âœ… æ²¡æœ‰ç©ºåˆ†ç»„éœ€è¦æ¸…ç†")
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {locale_file} æ—¶å‡ºé”™: {e}")
    
    if dry_run:
        print(f"\nğŸ“‹ é¢„è§ˆå®Œæˆï¼å…±å‘ç° {total_cleaned} ä¸ªç©ºåˆ†ç»„ã€‚è¦æ‰§è¡Œå®é™…æ¸…ç†ï¼Œè¯·ç§»é™¤ --dry-run å‚æ•°")
    else:
        print(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼å…±æ¸…ç†äº† {total_cleaned} ä¸ªç©ºåˆ†ç»„")

def remove_empty_groups(data: Any) -> Tuple[Any, int]:
    """é€’å½’ç§»é™¤ç©ºåˆ†ç»„ï¼Œè¿”å›æ¸…ç†åçš„æ•°æ®å’Œç§»é™¤çš„åˆ†ç»„æ•°é‡"""
    if not isinstance(data, dict):
        return data, 0
    
    result = {}
    removed_count = 0
    
    for key, value in data.items():  # type: ignore
        if isinstance(value, dict):
            if len(value) == 0:  # type: ignore
                # ç©ºå­—å…¸ï¼Œè·³è¿‡ï¼ˆä¸æ·»åŠ åˆ°ç»“æœä¸­ï¼‰
                removed_count += 1
                print(f"    - ç§»é™¤ç©ºåˆ†ç»„: {key}")
            else:
                # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                cleaned_value, nested_removed = remove_empty_groups(value)
                removed_count += nested_removed
                
                # å¦‚æœæ¸…ç†åä»ç„¶ä¸ä¸ºç©ºï¼Œåˆ™ä¿ç•™
                if isinstance(cleaned_value, dict) and len(cleaned_value) > 0:  # type: ignore
                    result[key] = cleaned_value
                elif not isinstance(cleaned_value, dict):
                    result[key] = cleaned_value
                else:
                    # æ¸…ç†åå˜ä¸ºç©ºå­—å…¸ï¼Œç§»é™¤
                    removed_count += 1
                    print(f"    - ç§»é™¤æ¸…ç†åå˜ç©ºçš„åˆ†ç»„: {key}")
        else:
            # éå­—å…¸å€¼ï¼Œç›´æ¥ä¿ç•™
            result[key] = value
    
    return result, removed_count  # type: ignore

def find_all_key_references(src_dir: str) -> Dict[str, List[Tuple[str, int, str]]]:
    """æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰translateè°ƒç”¨åŠå…¶ä½ç½®
    
    Returns:
        Dict[key, List[Tuple[file_path, line_number, full_line]]]
    """
    import re
    
    key_references: Dict[str, List[Tuple[str, int, str]]] = {}
    
    # åŒ¹é…translateè°ƒç”¨çš„æ­£åˆ™è¡¨è¾¾å¼
    translate_pattern = re.compile(r'translate\(["\']([^"\']+)["\']\)')
    
    for root, _, files in os.walk(src_dir):
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    for line_num, line in enumerate(lines, 1):
                        matches = translate_pattern.findall(line)
                        for key in matches:
                            if key not in key_references:
                                key_references[key] = []
                            relative_path = os.path.relpath(file_path, src_dir)
                            key_references[key].append((relative_path, line_num, line.strip()))
                            
                except Exception as e:
                    print(f"âš ï¸ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    return key_references

def update_code_references_smart(src_dir: str, old_key: str, new_key: str, dry_run: bool = True) -> None:
    """æ™ºèƒ½æ›´æ–°ä»£ç ä¸­çš„é”®å¼•ç”¨ï¼Œæ”¯æŒçˆ¶çº§é”®é‡å‘½å"""
    print(f"\n=== æ™ºèƒ½æ›´æ–°ä»£ç å¼•ç”¨ {'(é¢„è§ˆæ¨¡å¼)' if dry_run else '(æ‰§è¡Œæ¨¡å¼)'} ===")
    print(f"ä»: {old_key}")
    print(f"åˆ°: {new_key}")
    
    # é¦–å…ˆæ‰«ææ‰€æœ‰é”®å¼•ç”¨
    print("ğŸ” æ‰«æä»£ç ä¸­çš„æ‰€æœ‰é”®å¼•ç”¨...")
    all_references = find_all_key_references(src_dir)
    
    # æ‰¾å‡ºéœ€è¦æ›´æ–°çš„é”®
    keys_to_update: List[Tuple[str, str]] = []
    
    # 1. ç²¾ç¡®åŒ¹é…
    if old_key in all_references:
        keys_to_update.append((old_key, new_key))
    
    # 2. å‰ç¼€åŒ¹é…ï¼ˆå¤„ç†çˆ¶çº§é”®é‡å‘½åï¼‰
    old_key_prefix = old_key + "."
    new_key_prefix = new_key + "."
    
    for key in all_references:
        if key.startswith(old_key_prefix):
            # è®¡ç®—æ–°çš„é”®å
            suffix = key[len(old_key_prefix):]
            new_full_key = new_key_prefix + suffix
            keys_to_update.append((key, new_full_key))
    
    if not keys_to_update:
        print(f"â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°å¯¹é”® '{old_key}' æˆ–å…¶å­é”®çš„å¼•ç”¨")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(keys_to_update)} ä¸ªéœ€è¦æ›´æ–°çš„é”®:")
    for old_k, new_k in keys_to_update:
        ref_count = len(all_references[old_k])
        print(f"  â€¢ {old_k} â†’ {new_k} ({ref_count} å¤„å¼•ç”¨)")
    
    # æŒ‰æ–‡ä»¶åˆ†ç»„æ›´æ–°
    files_to_update: Dict[str, List[Tuple[str, str]]] = {}
    
    for old_k, new_k in keys_to_update:
        for file_path, _, _ in all_references[old_k]:
            full_file_path = os.path.join(src_dir, file_path)
            if full_file_path not in files_to_update:
                files_to_update[full_file_path] = []
            files_to_update[full_file_path].append((old_k, new_k))
    
    # æ‰§è¡Œæ–‡ä»¶æ›´æ–°
    updated_files = 0
    total_replacements = 0
    
    for file_path, key_pairs in files_to_update.items():
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            new_content = content
            file_replacements = 0
            
            # æŒ‰é”®é•¿åº¦é™åºæ’åºï¼Œé¿å…çŸ­é”®æ›¿æ¢é•¿é”®çš„é—®é¢˜
            key_pairs.sort(key=lambda x: len(x[0]), reverse=True)
            
            for old_k, new_k in key_pairs:
                # ç²¾ç¡®æ›¿æ¢
                patterns = [
                    (f'translate("{old_k}")', f'translate("{new_k}")'),
                    (f"translate('{old_k}')", f"translate('{new_k}')"),
                ]
                
                for old_pattern, new_pattern in patterns:
                    if old_pattern in new_content:
                        count = new_content.count(old_pattern)
                        new_content = new_content.replace(old_pattern, new_pattern)
                        file_replacements += count
            
            if file_replacements > 0:
                relative_path = os.path.relpath(file_path, src_dir)
                print(f"ğŸ“ {relative_path}: {file_replacements} å¤„æ›¿æ¢")
                
                if not dry_run:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                
                updated_files += 1
                total_replacements += file_replacements
                
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    if dry_run:
        print(f"\nğŸ“‹ é¢„è§ˆå®Œæˆï¼å°†åœ¨ {updated_files} ä¸ªæ–‡ä»¶ä¸­è¿›è¡Œ {total_replacements} å¤„æ›¿æ¢")
    else:
        print(f"\nâœ… æ›´æ–°å®Œæˆï¼åœ¨ {updated_files} ä¸ªæ–‡ä»¶ä¸­è¿›è¡Œäº† {total_replacements} å¤„æ›¿æ¢")

def update_code_references(src_dir: str, old_key: str, new_key: str, dry_run: bool = True) -> None:
    """æ›´æ–°ä»£ç ä¸­çš„é”®å¼•ç”¨ï¼ˆå…¼å®¹æ€§åŒ…è£…ï¼‰"""
    update_code_references_smart(src_dir, old_key, new_key, dry_run)

def main() -> None:
    parser = argparse.ArgumentParser(description='æœ¬åœ°åŒ–ç®¡ç†å·¥å…·')
    parser.add_argument('--src-dir', default='src', help='æºä»£ç ç›®å½• (é»˜è®¤: src)')
    parser.add_argument('--locales', nargs='+', 
                       default=['src/locales/zh.yml', 'src/locales/en.yml', 'src/locales/ja.yml'],
                       help='è¯­è¨€æ–‡ä»¶è·¯å¾„åˆ—è¡¨')
    parser.add_argument('--dry-run', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…ä¿®æ”¹')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ†æå‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='åˆ†ææœ¬åœ°åŒ–é”®ä½¿ç”¨æƒ…å†µ')
    analyze_parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # æ£€æŸ¥ä¸€è‡´æ€§å‘½ä»¤
    subparsers.add_parser('check', help='æ£€æŸ¥è¯­è¨€æ–‡ä»¶ä¸€è‡´æ€§')
    
    # åˆ—å‡ºä½¿ç”¨çš„é”®å‘½ä»¤
    subparsers.add_parser('list-used', help='åˆ—å‡ºä»£ç ä¸­ä½¿ç”¨çš„æ‰€æœ‰é”®')
    
    # åˆ—å‡ºå®šä¹‰çš„é”®å‘½ä»¤
    subparsers.add_parser('list-defined', help='åˆ—å‡ºè¯­è¨€æ–‡ä»¶ä¸­å®šä¹‰çš„æ‰€æœ‰é”®')
    
    # æŒ‰æ–‡ä»¶åˆ—å‡ºä½¿ç”¨çš„é”®å‘½ä»¤
    subparsers.add_parser('list-by-file', help='æŒ‰æ–‡ä»¶åˆ†ç»„åˆ—å‡ºä½¿ç”¨çš„æœ¬åœ°åŒ–é”®')
    
    # åˆ†æé”®å¼•ç”¨å‘½ä»¤
    ref_parser = subparsers.add_parser('analyze-refs', help='åˆ†æé”®å¼•ç”¨è¯¦æƒ…')
    ref_parser.add_argument('key_pattern', nargs='?', help='é”®æ¨¡å¼ï¼ˆå¯é€‰ï¼Œæ”¯æŒå‰ç¼€åŒ¹é…ï¼‰')
    
    # æŸ¥æ‰¾æœªä½¿ç”¨çš„é”®å‘½ä»¤
    subparsers.add_parser('find-unused', help='æŸ¥æ‰¾æœªä½¿ç”¨çš„é”®')
    
    # æ¸…ç†æœªä½¿ç”¨çš„é”®å‘½ä»¤
    subparsers.add_parser('clean', help='æ¸…ç†æœªä½¿ç”¨çš„é”®')
    
    # æ¸…ç†ç©ºç»„å‘½ä»¤
    subparsers.add_parser('clean-empty', help='æ¸…ç†ç©ºçš„åˆ†ç»„')
    
    # é‡å‘½åé”®å‘½ä»¤
    rename_parser = subparsers.add_parser('rename', help='é‡å‘½åæœ¬åœ°åŒ–é”®')
    rename_parser.add_argument('old_key', help='æ—§é”®å')
    rename_parser.add_argument('new_key', help='æ–°é”®å')
    rename_parser.add_argument('--update-code', action='store_true', help='åŒæ—¶æ›´æ–°ä»£ç ä¸­çš„å¼•ç”¨')
    
    # ç§»åŠ¨é”®åˆ°æ–°åˆ†ç»„å‘½ä»¤
    move_parser = subparsers.add_parser('move', help='ç§»åŠ¨é”®åˆ°æ–°åˆ†ç»„')
    move_parser.add_argument('old_key', help='è¦ç§»åŠ¨çš„é”®')
    move_parser.add_argument('new_group', help='ç›®æ ‡åˆ†ç»„')
    move_parser.add_argument('--update-code', action='store_true', help='åŒæ—¶æ›´æ–°ä»£ç ä¸­çš„å¼•ç”¨')
    
    # æ‰¹é‡é‡å‘½åå‘½ä»¤
    batch_parser = subparsers.add_parser('batch-rename', help='æ‰¹é‡é‡å‘½åé”®')
    batch_parser.add_argument('mapping_file', help='åŒ…å«é‡å‘½åæ˜ å°„çš„YAMLæ–‡ä»¶')
    batch_parser.add_argument('--update-code', action='store_true', help='åŒæ—¶æ›´æ–°ä»£ç ä¸­çš„å¼•ç”¨')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    src_dir = os.path.abspath(args.src_dir)
    locale_files = [os.path.abspath(f) for f in args.locales]
    
    if args.command == 'analyze':
        analysis = analyze_usage(src_dir, locale_files)
        print_usage_report(analysis)
        
        if args.verbose:
            print(f"\n=== è¯¦ç»†ä¿¡æ¯ ===")
            print(f"æºä»£ç ç›®å½•: {src_dir}")
            print(f"è¯­è¨€æ–‡ä»¶: {locale_files}")
    
    elif args.command == 'check':
        is_consistent, errors = check_consistency(locale_files)
        
        if is_consistent:
            print("âœ… æ‰€æœ‰è¯­è¨€æ–‡ä»¶çš„é”®éƒ½æ˜¯ä¸€è‡´çš„ï¼")
        else:
            print("âŒ è¯­è¨€æ–‡ä»¶é”®ä¸ä¸€è‡´:")
            for error in errors:
                print(f"  - {error}")
    
    elif args.command == 'list-used':
        used_keys = extract_used_keys(src_dir)
        print(f"=== ä»£ç ä¸­ä½¿ç”¨çš„æœ¬åœ°åŒ–é”® ({len(used_keys)} ä¸ª) ===")
        for key in sorted(used_keys):
            print(key)
    
    elif args.command == 'list-defined':
        defined_keys = extract_defined_keys(locale_files)
        print(f"=== è¯­è¨€æ–‡ä»¶ä¸­å®šä¹‰çš„é”® ({len(defined_keys)} ä¸ª) ===")
        for key in sorted(defined_keys):
            print(key)
    
    elif args.command == 'list-by-file':
        file_keys = extract_used_keys_by_file(src_dir)
        print_keys_by_file(file_keys)
    
    elif args.command == 'analyze-refs':
        all_references = find_all_key_references(src_dir)
        
        if args.key_pattern:
            # è¿‡æ»¤åŒ¹é…çš„é”®
            filtered_refs: Dict[str, List[Tuple[str, int, str]]] = {}
            pattern: str = args.key_pattern
            for key, refs in all_references.items():
                if key == pattern or key.startswith(pattern + "."):
                    filtered_refs[key] = refs
            
            if filtered_refs:
                print(f"=== é”®å¼•ç”¨åˆ†æ: {pattern} ===")
                for key in sorted(filtered_refs.keys()):
                    refs = filtered_refs[key]
                    print(f"\nğŸ”‘ {key} ({len(refs)} å¤„å¼•ç”¨)")
                    for file_path, line_num, line_content in refs:
                        print(f"  ğŸ“„ {file_path}:{line_num} - {line_content}")
            else:
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é… '{pattern}' çš„é”®å¼•ç”¨")
        else:
            # æ˜¾ç¤ºæ‰€æœ‰é”®çš„ç»Ÿè®¡
            print(f"=== æ‰€æœ‰é”®å¼•ç”¨ç»Ÿè®¡ ===")
            print(f"æ€»é”®æ•°: {len(all_references)}")
            
            # æŒ‰å¼•ç”¨æ¬¡æ•°æ’åº
            sorted_keys = sorted(all_references.items(), key=lambda x: len(x[1]), reverse=True)
            
            print(f"\nğŸ“Š å¼•ç”¨æ¬¡æ•°æœ€å¤šçš„å‰10ä¸ªé”®:")
            for i, (key, refs) in enumerate(sorted_keys[:10], 1):
                print(f"{i:2d}. {key} ({len(refs)} å¤„)")
            
            print(f"\nğŸ“Š æŒ‰å‰ç¼€åˆ†ç»„ç»Ÿè®¡:")
            prefix_stats: Dict[str, int] = {}
            for key in all_references:
                if '.' in key:
                    prefix = key.split('.')[0]
                    prefix_stats[prefix] = prefix_stats.get(prefix, 0) + 1
            
            for prefix in sorted(prefix_stats.keys()):
                count = prefix_stats[prefix]
                print(f"  {prefix}.*: {count} ä¸ªé”®")
    
    elif args.command == 'find-unused':
        analysis = analyze_usage(src_dir, locale_files)
        
        if analysis['unused_keys']:
            print(f"=== æœªä½¿ç”¨çš„é”® ({analysis['total_unused']} ä¸ª) ===")
            for key in sorted(analysis['unused_keys']):
                print(key)
        else:
            print("âœ… æ‰€æœ‰é”®éƒ½è¢«ä½¿ç”¨äº†ï¼")
    
    elif args.command == 'clean':
        analysis = analyze_usage(src_dir, locale_files)
        
        if analysis['unused_keys']:
            clean_unused_keys(locale_files, analysis['unused_keys'], dry_run=args.dry_run)
        else:
            print("âœ… æ²¡æœ‰æœªä½¿ç”¨çš„é”®éœ€è¦æ¸…ç†ï¼")
    
    elif args.command == 'clean-empty':
        clean_empty_groups(locale_files, dry_run=args.dry_run)
    
    elif args.command == 'rename':
        rename_key_in_files(locale_files, args.old_key, args.new_key, dry_run=args.dry_run)
        
        if args.update_code:
            update_code_references(src_dir, args.old_key, args.new_key, dry_run=args.dry_run)
    
    elif args.command == 'move':
        move_key_to_group(locale_files, args.old_key, args.new_group, dry_run=args.dry_run)
        
        if args.update_code:
            # è®¡ç®—æ–°é”®å
            key_parts = args.old_key.split('.')
            key_name = key_parts[-1]
            new_key = f"{args.new_group}.{key_name}"
            update_code_references(src_dir, args.old_key, new_key, dry_run=args.dry_run)
    
    elif args.command == 'batch-rename':
        batch_rename_keys(locale_files, args.mapping_file, dry_run=args.dry_run)
        
        if args.update_code:
            # å¯¹äºæ‰¹é‡é‡å‘½åï¼Œéœ€è¦è¯»å–æ˜ å°„æ–‡ä»¶å¹¶é€ä¸ªæ›´æ–°ä»£ç å¼•ç”¨
            try:
                with open(args.mapping_file, 'r', encoding='utf-8') as f:
                    mappings: Any = yaml_loader.load(f)  # type: ignore
                
                if mappings and isinstance(mappings, dict):
                    for k, v in mappings.items():  # type: ignore
                        if isinstance(k, str) and isinstance(v, str):
                            update_code_references(src_dir, k, v, dry_run=args.dry_run)
            except Exception as e:
                print(f"âŒ æ›´æ–°ä»£ç å¼•ç”¨æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
